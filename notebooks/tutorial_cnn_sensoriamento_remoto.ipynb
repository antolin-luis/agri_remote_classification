{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Classificação Não Supervisionada de Imagens de Sensoriamento Remoto usando CNN\n",
    "\n",
    "Este notebook apresenta um guia passo a passo sobre como usar Redes Neurais Convolucionais (CNN) para classificação não supervisionada de imagens de sensoriamento remoto do Sentinel-2.\n",
    "\n",
    "## Conteúdo:\n",
    "1. Introdução ao Sensoriamento Remoto e CNNs\n",
    "2. Preparação dos Dados\n",
    "3. Implementação do Modelo\n",
    "4. Treinamento e Validação\n",
    "5. Visualização e Análise dos Resultados\n",
    "\n",
    "## 1. Introdução\n",
    "\n",
    "### 1.1 Sensoriamento Remoto\n",
    "O sensoriamento remoto é a técnica de obter informações sobre objetos ou áreas através de dados coletados por instrumentos que não estão em contato direto com os objetos de investigação. No nosso caso, usaremos imagens do satélite Sentinel-2, que fornece imagens multiespectrais de alta resolução.\n",
    "\n",
    "### 1.2 Por que usar CNN?\n",
    "CNNs são especialmente eficazes para processamento de imagens porque:\n",
    "- Podem aprender hierarquias de características automaticamente\n",
    "- São invariantes a translações\n",
    "- Podem capturar padrões espaciais complexos\n",
    "\n",
    "### 1.3 Abordagem Não Supervisionada\n",
    "Usaremos um autoencoder com clustering para identificar padrões nas imagens sem necessidade de rótulos, o que é especialmente útil quando não temos dados rotulados disponíveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparação do Ambiente\n",
    "\n",
    "Primeiro, vamos importar as bibliotecas necessárias e configurar nosso ambiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.data.tiff_loader import TiffLoader\n",
    "from src.models.unsupervised_cnn import UnsupervisedCNN\n",
    "import mlflow\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurar o estilo dos gráficos\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carregamento e Preparação dos Dados\n",
    "\n",
    "### 3.1 Entendendo as Bandas do Sentinel-2\n",
    "\n",
    "Neste projeto, usamos três bandas específicas do Sentinel-2:\n",
    "- **B8 (NIR)**: Infravermelho próximo (842nm) - Útil para análise de vegetação\n",
    "- **B4 (Red)**: Vermelho (665nm) - Absorção de clorofila\n",
    "- **B11 (SWIR)**: Infravermelho de onda curta (1610nm) - Sensível à umidade\n",
    "\n",
    "### 3.2 Carregando os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Inicializar o loader\n",
    "loader = TiffLoader(\n",
    "    train_val_dir='../data/train',  # Ajuste o caminho conforme necessário\n",
    "    prediction_dir='../data/predict',\n",
    "    patch_size=64\n",
    ")\n",
    "\n",
    "# Carregar dados de treino e validação\n",
    "train_ds, val_ds = loader.load_train_val_data(val_split=0.2)\n",
    "\n",
    "# Preparar os datasets\n",
    "train_ds = loader.prepare_dataset(train_ds, batch_size=32, shuffle=True, augment=True)\n",
    "val_ds = loader.prepare_dataset(val_ds, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Visualizando os Dados\n",
    "\n",
    "Vamos visualizar alguns exemplos dos nossos patches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def plot_patches(dataset, num_patches=5):\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i, batch in enumerate(dataset.take(1)):\n",
    "        for j in range(num_patches):\n",
    "            plt.subplot(1, num_patches, j+1)\n",
    "            # Composição RGB usando as bandas disponíveis\n",
    "            rgb = batch[j].numpy()\n",
    "            plt.imshow(rgb)\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Patch {j+1}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_patches(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementação e Treinamento do Modelo\n",
    "\n",
    "### 4.1 Arquitetura do Modelo\n",
    "\n",
    "Nosso modelo consiste em duas partes principais:\n",
    "1. **Autoencoder**: Para aprender uma representação compacta dos dados\n",
    "2. **K-means**: Para clustering no espaço latente\n",
    "\n",
    "### 4.2 Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Inicializar o modelo\n",
    "model = UnsupervisedCNN(\n",
    "    input_shape=(64, 64, 3),\n",
    "    n_clusters=5,\n",
    "    latent_dim=128,\n",
    "    experiment_name='tutorial_sentinel2'\n",
    ")\n",
    "\n",
    "# Converter dataset para numpy array para treinamento\n",
    "X_train = np.concatenate([batch.numpy() for batch in train_ds], axis=0)\n",
    "\n",
    "# Treinar o modelo\n",
    "model.train(\n",
    "    X=X_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    model_params={'description': 'Tutorial Sentinel-2'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análise dos Resultados\n",
    "\n",
    "### 5.1 Visualização dos Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Fazer predições\n",
    "predictions = model.predict(X_train)\n",
    "\n",
    "# Visualizar exemplos de cada cluster\n",
    "plt.figure(figsize=(15, 3*model.n_clusters))\n",
    "for cluster in range(model.n_clusters):\n",
    "    cluster_samples = X_train[predictions == cluster][:5]\n",
    "    for j, sample in enumerate(cluster_samples):\n",
    "        plt.subplot(model.n_clusters, 5, cluster*5 + j + 1)\n",
    "        plt.imshow(sample)\n",
    "        plt.axis('off')\n",
    "        if j == 0:\n",
    "            plt.ylabel(f'Cluster {cluster}')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Análise do Espaço Latente\n",
    "\n",
    "Vamos visualizar como as amostras estão distribuídas no espaço latente usando PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Obter representações latentes\n",
    "latent_features = model.encoder.predict(X_train)\n",
    "\n",
    "# Reduzir dimensionalidade para visualização\n",
    "pca = PCA(n_components=2)\n",
    "latent_2d = pca.fit_transform(latent_features)\n",
    "\n",
    "# Plotar\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=predictions, cmap='viridis')\n",
    "plt.colorbar(scatter)\n",
    "plt.title('Distribuição das Amostras no Espaço Latente')\n",
    "plt.xlabel('Primeira Componente Principal')\n",
    "plt.ylabel('Segunda Componente Principal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interpretação dos Resultados\n",
    "\n",
    "### 6.1 Características dos Clusters\n",
    "\n",
    "Cada cluster identificado pode representar diferentes tipos de cobertura do solo ou características da paisagem. Por exemplo:\n",
    "- Áreas urbanas\n",
    "- Vegetação densa\n",
    "- Solo exposto\n",
    "- Corpos d'água\n",
    "- Áreas agrícolas\n",
    "\n",
    "### 6.2 Limitações e Considerações\n",
    "\n",
    "É importante notar algumas limitações desta abordagem:\n",
    "1. O número de clusters é definido manualmente\n",
    "2. A interpretação dos clusters requer conhecimento do domínio\n",
    "3. A qualidade do clustering pode variar dependendo da representatividade dos dados\n",
    "\n",
    "## 7. Próximos Passos\n",
    "\n",
    "Para melhorar os resultados, você pode:\n",
    "1. Experimentar com diferentes números de clusters\n",
    "2. Ajustar a arquitetura do autoencoder\n",
    "3. Incluir mais bandas espectrais\n",
    "4. Usar técnicas de validação mais robustas\n",
    "5. Incorporar conhecimento do domínio na interpretação dos resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
